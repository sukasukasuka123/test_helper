"""
Agent å·¥å…·é›†ï¼ˆLangChain ç‰ˆæœ¬ï¼Œä½¿ç”¨ @tool è£…é¥°å™¨ï¼Œå‡½æ•°æ¥æ”¶æ™®é€šç±»å‹å‚æ•°ï¼‰
æ‰€æœ‰å·¥å…·å‡ç”¨ @tool æ³¨è§£å®šä¹‰ï¼Œå¹¶ä¿ç•™ Pydantic è¾“å…¥æ¨¡å‹ç”¨äºæè¿°å’ŒéªŒè¯
æ”¯æŒï¼šå§“åæ¨¡ç³ŠåŒ¹é…ã€æ‰¹é‡å¤„ç†ã€å‘é€é‚®ä»¶ã€é‚®ä»¶é™„ä»¶ä¸‹è½½ã€æŠ¥åè¡¨ç´¢å¼•ä¸è¯»å–
"""
import json
import smtplib
import os
import imaplib
import email
import re
import sqlite3
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from email.header import decode_header
from typing import Dict, Any, List, Optional, Union
from pathlib import Path
from dotenv import load_dotenv

load_dotenv()  # åŠ è½½é¡¹ç›®æ ¹ç›®å½•çš„ .env æ–‡ä»¶

from langchain_core.tools import tool
from pydantic import BaseModel, Field, ValidationError

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 163é‚®ç®± IMAP å…¼å®¹æ€§è¡¥ä¸
# å¿…é¡»åœ¨æ¨¡å—åŠ è½½æ—¶æ³¨å†Œï¼Œå¦åˆ™ _simple_command('ID', ...) ä¼šæŠ›å‡º KeyError
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
imaplib.Commands['ID'] = ('AUTH',)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Pydantic å‚æ•° Schemaï¼ˆç”¨äºæè¿°å’ŒéªŒè¯ï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class LookupNameInput(BaseModel):
    """å§“åæŸ¥æ‰¾å·¥å…·è¾“å…¥å‚æ•°"""
    name: str = Field(default="", description="é¢è¯•è€…å§“åï¼Œæ”¯æŒæ¨¡ç³ŠåŒ¹é…ï¼›ä¼ ç©ºå­—ç¬¦ä¸²å¯åˆ—å‡ºæ‰€æœ‰äºº")


class AnalyzeInput(BaseModel):
    """é¢è¯•è€…åˆ†æå·¥å…·è¾“å…¥å‚æ•°"""
    interviewee_ids: List[int] = Field(..., description="é¢è¯•è€… ID åˆ—è¡¨ï¼Œå¯ä¼ å¤šä¸ª")


class ReportInput(BaseModel):
    """æŠ¥å‘Šç”Ÿæˆå·¥å…·è¾“å…¥å‚æ•°"""
    interviewee_ids: List[int] = Field(..., description="é¢è¯•è€… ID åˆ—è¡¨")


class RecommendInput(BaseModel):
    """é¢˜ç›®æ¨èå·¥å…·è¾“å…¥å‚æ•°"""
    interviewee_ids: List[int] = Field(..., description="é¢è¯•è€… ID åˆ—è¡¨")
    num_questions: int = Field(default=3, description="æ¯äººæ¨èé¢˜ç›®æ•°é‡", ge=1, le=20)


class EmailRecipient(BaseModel):
    """é‚®ä»¶æ”¶ä»¶äººä¿¡æ¯"""
    interviewee_id: int = Field(..., description="é¢è¯•è€… IDï¼ˆç”¨äºæŸ¥è¯¢é‚®ç®±ï¼‰")
    report_content: str = Field(..., description="é‚®ä»¶æ­£æ–‡ï¼ˆé€šå¸¸æ˜¯æŠ¥å‘Šæ–‡æœ¬ï¼‰")
    subject: Optional[str] = Field(default="æ‚¨çš„é¢è¯•æŠ¥å‘Š", description="é‚®ä»¶ä¸»é¢˜")


class SendEmailInput(BaseModel):
    """å‘é€é‚®ä»¶å·¥å…·è¾“å…¥å‚æ•°"""
    recipients: List[EmailRecipient] = Field(..., description="æ”¶ä»¶äººåˆ—è¡¨ï¼Œæ”¯æŒæ‰¹é‡å‘é€")


class GetDocInput(BaseModel):
    """è·å–é‚®ä»¶é™„ä»¶å·¥å…·è¾“å…¥å‚æ•°"""
    save_dir: str = Field(default="./attachments", description="é™„ä»¶ä¿å­˜ç›®å½•è·¯å¾„")
    subject_filter: Optional[str] = Field(default=None, description="é‚®ä»¶ä¸»é¢˜å…³é”®è¯è¿‡æ»¤ï¼Œä¸ºç©ºåˆ™è·å–æ‰€æœ‰å«é™„ä»¶é‚®ä»¶")
    sender_filter: Optional[str] = Field(default=None, description="å‘ä»¶äººé‚®ç®±è¿‡æ»¤ï¼Œä¸ºç©ºåˆ™ä¸é™åˆ¶")
    max_emails: int = Field(default=50, description="æœ€å¤šæ‰«æé‚®ä»¶æ•°é‡", ge=1, le=500)
    file_extensions: List[str] = Field(
        default=[".pdf", ".docx", ".doc", ".xlsx", ".xls", ".png", ".jpg", ".jpeg"],
        description="å…è®¸ä¸‹è½½çš„é™„ä»¶æ‰©å±•ååˆ—è¡¨"
    )


class WriteKeyInput(BaseModel):
    """å»ºç«‹æŠ¥åè¡¨ç´¢å¼•å·¥å…·è¾“å…¥å‚æ•°"""
    attachments_dir: str = Field(default="./attachments", description="é™„ä»¶æ‰€åœ¨ç›®å½•è·¯å¾„")
    name_pattern: Optional[str] = Field(
        default=None,
        description="ä»æ–‡ä»¶åä¸­æå–å§“åçš„æ­£åˆ™è¡¨è¾¾å¼ï¼ˆå«æ•è·ç»„ï¼‰ï¼Œå¦‚ r'æŠ¥åè¡¨_(.+?)_\\d+'"
    )
    id_pattern: Optional[str] = Field(
        default=None,
        description="ä»æ–‡ä»¶åä¸­æå–å­¦å·çš„æ­£åˆ™è¡¨è¾¾å¼ï¼ˆå«æ•è·ç»„ï¼‰ï¼Œå¦‚ r'_(\\d{8,12})'"
    )


class ReadDocInput(BaseModel):
    """è¯»å–æŠ¥åè¡¨å†…å®¹å·¥å…·è¾“å…¥å‚æ•°"""
    file_path: str = Field(..., description="æŠ¥åè¡¨æ–‡ä»¶çš„å®Œæ•´è·¯å¾„")
    extract_fields: List[str] = Field(
        default=["å§“å", "å­¦å·", "ä¸“ä¸š", "å¹´çº§", "è”ç³»æ–¹å¼", "é‚®ç®±", "æ„å‘éƒ¨é—¨"],
        description="éœ€è¦ä»æŠ¥åè¡¨ä¸­æå–çš„å­—æ®µååˆ—è¡¨"
    )


class ReadKeyInput(BaseModel):
    """é€šè¿‡æ•°æ®åº“æŸ¥è¯¢ç´¢å¼•å†…å®¹å·¥å…·è¾“å…¥å‚æ•°"""
    name: Optional[str] = Field(default=None, description="æŒ‰å§“åæ¨¡ç³ŠæŸ¥è¯¢ï¼Œä¸ºç©ºåˆ™åˆ—å‡ºæ‰€æœ‰")
    student_id: Optional[str] = Field(default=None, description="æŒ‰å­¦å·ç²¾ç¡®æŸ¥è¯¢")
    limit: int = Field(default=50, description="æœ€å¤šè¿”å›æ¡æ•°", ge=1, le=500)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# æ•°æ®åº“è¾…åŠ©ï¼šç¡®ä¿æŠ¥åè¡¨ç´¢å¼•è¡¨å­˜åœ¨
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _ensure_registration_table(db):
    """
    æ£€æŸ¥å¹¶åˆ›å»º registration_index è¡¨ï¼ˆè‹¥ä¸å­˜åœ¨ï¼‰ã€‚
    è¡¨ç»“æ„ï¼šid, name, student_id, file_path, file_name, created_at
    """
    db.execute("""
        CREATE TABLE IF NOT EXISTS registration_index (
            id          INTEGER PRIMARY KEY AUTOINCREMENT,
            name        TEXT,
            student_id  TEXT,
            file_path   TEXT NOT NULL UNIQUE,
            file_name   TEXT,
            created_at  DATETIME DEFAULT CURRENT_TIMESTAMP
        )
    """)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1. å§“åæŸ¥æ‰¾å·¥å…·
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _create_lookup_tool(db):
    """å·¥å‚å‡½æ•°ï¼šåˆ›å»ºå§“åæŸ¥æ‰¾å·¥å…·"""

    @tool(args_schema=LookupNameInput)
    def lookup_interviewees_by_name(name: str) -> str:
        """æŒ‰å§“åï¼ˆæ”¯æŒæ¨¡ç³ŠåŒ¹é…ï¼‰æŸ¥æ‰¾é¢è¯•è€…ï¼Œè¿”å›åŒ¹é…çš„ ID åˆ—è¡¨åŠåŸºæœ¬ä¿¡æ¯ã€‚å½“ç”¨æˆ·æåˆ°äººåæ—¶ï¼Œå¿…é¡»å…ˆè°ƒç”¨æ­¤å·¥å…·è·å– interviewee_idã€‚"""
        name_val = name.strip() if name else ""
        if name_val:
            rows = db.fetchall(
                "SELECT id, name, email, phone FROM interviewee WHERE name LIKE ?",
                (f"%{name_val}%",)
            )
        else:
            rows = db.fetchall("SELECT id, name, email, phone FROM interviewee")

        if not rows:
            return f"æœªæ‰¾åˆ°å§“ååŒ…å«ã€Œ{name_val}ã€çš„é¢è¯•è€…" if name_val else "æš‚æ— é¢è¯•è€…è®°å½•"

        result = f"æŸ¥æ‰¾ç»“æœï¼ˆå…± {len(rows)} äººï¼‰:\n"
        for iid, iname, email, phone in rows:
            result += f"  - ID:{iid}  å§“å:{iname}  é‚®ç®±:{email or 'æœªå¡«å†™'}  ç”µè¯:{phone or 'æœªå¡«å†™'}\n"
        return result

    return lookup_interviewees_by_name


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2. é¢˜åº“ç»Ÿè®¡å·¥å…·ï¼ˆæ— å‚æ•°ï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _create_question_stats_tool(db):
    """å·¥å‚å‡½æ•°ï¼šåˆ›å»ºé¢˜åº“ç»Ÿè®¡å·¥å…·"""

    @tool
    def get_question_statistics() -> str:
        """è·å–é¢˜åº“ç»Ÿè®¡ä¿¡æ¯ï¼ŒåŒ…æ‹¬å„ç±»å‹ã€å„éš¾åº¦çš„é¢˜ç›®æ•°é‡åˆ†å¸ƒ"""
        total = db.fetchall("SELECT COUNT(*) FROM question_bank")[0][0]

        type_stats = db.fetchall("""
            SELECT q_type, COUNT(*) as count
            FROM question_bank
            GROUP BY q_type
            ORDER BY count DESC
        """)
        diff_stats = db.fetchall("""
            SELECT difficulty, COUNT(*) as count
            FROM question_bank
            GROUP BY difficulty
            ORDER BY count DESC
        """)

        result = f"é¢˜åº“ç»Ÿè®¡\næ€»é¢˜æ•°: {total} é“\n\nç±»å‹åˆ†å¸ƒ:\n"
        for q_type, count in type_stats:
            result += f"  {q_type}: {count} é“\n"
        result += "\néš¾åº¦åˆ†å¸ƒ:\n"
        for difficulty, count in diff_stats:
            result += f"  {difficulty}: {count} é“\n"
        return result

    return get_question_statistics


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3. é¢è¯•è€…åˆ†æå·¥å…·ï¼ˆæ”¯æŒæ‰¹é‡ï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _create_analysis_tool(db):
    """å·¥å‚å‡½æ•°ï¼šåˆ›å»ºé¢è¯•è€…åˆ†æå·¥å…·"""

    def _analyze_one(interviewee_id: int) -> str:
        info = db.fetchall(
            "SELECT name, email, created_at FROM interviewee WHERE id=?",
            (interviewee_id,)
        )
        if not info:
            return f"æœªæ‰¾åˆ°é¢è¯•è€… ID={interviewee_id}"

        name, email, created_at = info[0]
        records = db.fetchall(
            "SELECT score, answer_snapshot FROM interview_record WHERE interviewee_id=?",
            (interviewee_id,)
        )

        if not records:
            return f"[{name}] å°šæ— ç­”é¢˜è®°å½•"

        scores = [r[0] for r in records]
        avg_score = round(sum(scores) / len(scores), 2)

        type_scores: Dict[str, List] = {}
        for score, snap_json in records:
            snap = json.loads(snap_json)
            q_type = snap.get("type", "æœªçŸ¥")
            type_scores.setdefault(q_type, []).append(score)

        rating = (
            "ä¼˜ç§€" if avg_score >= 8 else
            "è‰¯å¥½" if avg_score >= 6 else
            "åŠæ ¼" if avg_score >= 4 else "å¾…æé«˜"
        )

        result = (
            f"ã€{name}ã€‘(ID:{interviewee_id})\n"
            f"  é‚®ç®±: {email or 'æœªå¡«å†™'}  æ³¨å†Œ: {created_at}\n"
            f"  é¢˜æ•°: {len(scores)}  æ€»åˆ†: {sum(scores)}  å‡åˆ†: {avg_score}  "
            f"æœ€é«˜: {max(scores)}  æœ€ä½: {min(scores)}\n"
            f"  å„ç±»å‹å‡åˆ†:\n"
        )
        for q_type, sc_list in type_scores.items():
            result += f"    {q_type}: {round(sum(sc_list) / len(sc_list), 2)} åˆ† ({len(sc_list)} é¢˜)\n"
        result += f"  ç»¼åˆè¯„çº§: {rating}\n"
        return result

    @tool(args_schema=AnalyzeInput)
    def analyze_interviewees(interviewee_ids: List[int]) -> str:
        """åˆ†æä¸€ä¸ªæˆ–å¤šä¸ªé¢è¯•è€…çš„ç­”é¢˜è¡¨ç°ï¼ˆæ€»åˆ†ã€å‡åˆ†ã€å„ç±»å‹å¾—åˆ†ã€ç»¼åˆè¯„çº§ï¼‰ã€‚interviewee_ids ä¼ å…¥ ID æ•°ç»„ï¼Œæ”¯æŒæ‰¹é‡åˆ†æã€‚"""
        results = [_analyze_one(iid) for iid in interviewee_ids]
        return "\n\n" + ("=" * 60 + "\n").join(results)

    return analyze_interviewees


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4. æŠ¥å‘Šç”Ÿæˆå·¥å…·ï¼ˆæ”¯æŒæ‰¹é‡ï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _create_report_tool(db):
    """å·¥å‚å‡½æ•°ï¼šåˆ›å»ºæŠ¥å‘Šç”Ÿæˆå·¥å…·"""

    def _generate_one(interviewee_id: int) -> str:
        info = db.fetchall(
            "SELECT name, email, phone FROM interviewee WHERE id=?",
            (interviewee_id,)
        )
        if not info:
            return f"æœªæ‰¾åˆ°é¢è¯•è€… ID={interviewee_id}"

        name, email, phone = info[0]
        records = db.fetchall("""
            SELECT question_id, score, answer_snapshot, created_at
            FROM interview_record
            WHERE interviewee_id = ?
            ORDER BY created_at
        """, (interviewee_id,))

        if not records:
            return f"[{name}] æ— ç­”é¢˜è®°å½•ï¼Œæ— æ³•ç”ŸæˆæŠ¥å‘Š"

        sep = "=" * 60
        report = f"{sep}\n{'é¢è¯•æŠ¥å‘Š':^56}\n{sep}\n"
        report += f"å§“å: {name}  é‚®ç®±: {email or 'æœªå¡«å†™'}  ç”µè¯: {phone or 'æœªå¡«å†™'}\n\n"
        report += "ç­”é¢˜æ˜ç»†\n" + "-" * 60 + "\n"

        for idx, (q_id, score, snap_json, ans_time) in enumerate(records, 1):
            snap = json.loads(snap_json)
            report += (
                f"\né¢˜ç›® {idx}  ç±»å‹:{snap.get('type', 'æœªçŸ¥')}  "
                f"éš¾åº¦:{snap.get('difficulty', 'æœªçŸ¥')}  å¾—åˆ†:{score}\n"
                f"  å†…å®¹: {snap.get('content', '')[:60]}...\n"
                f"  æ—¶é—´: {ans_time}\n"
            )
            if snap.get("remark"):
                report += f"  å¤‡æ³¨: {snap['remark']}\n"

        scores = [r[1] for r in records]
        report += (
            f"\n{sep}\nç»Ÿè®¡åˆ†æ\n"
            f"  é¢˜æ•°:{len(scores)}  æ€»åˆ†:{sum(scores)}  "
            f"å‡åˆ†:{round(sum(scores) / len(scores), 2)}  "
            f"æœ€é«˜:{max(scores)}  æœ€ä½:{min(scores)}\n{sep}\n"
        )
        return report

    @tool(args_schema=ReportInput)
    def generate_reports(interviewee_ids: List[int]) -> str:
        """ä¸ºä¸€ä¸ªæˆ–å¤šä¸ªé¢è¯•è€…ç”Ÿæˆè¯¦ç»†é¢è¯•æŠ¥å‘Šï¼ˆç­”é¢˜æ˜ç»† + ç»Ÿè®¡åˆ†æï¼‰ã€‚è¿”å›æŠ¥å‘Šæ–‡æœ¬ï¼Œå¯é…åˆ send_report_email å·¥å…·å‘é€ç»™é¢è¯•è€…ã€‚"""
        reports = [_generate_one(iid) for iid in interviewee_ids]
        return "\n\n".join(reports)

    return generate_reports


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 5. é¢˜ç›®æ¨èå·¥å…·ï¼ˆæ”¯æŒæ‰¹é‡ï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _create_recommend_tool(db):
    """å·¥å‚å‡½æ•°ï¼šåˆ›å»ºé¢˜ç›®æ¨èå·¥å…·"""

    def _recommend_one(interviewee_id: int, num_questions: int) -> str:
        info = db.fetchall(
            "SELECT name FROM interviewee WHERE id=?", (interviewee_id,)
        )
        if not info:
            return f"æœªæ‰¾åˆ°é¢è¯•è€… ID={interviewee_id}"

        name = info[0][0]
        records = db.fetchall(
            "SELECT score, answer_snapshot FROM interview_record WHERE interviewee_id=?",
            (interviewee_id,)
        )

        if records:
            type_scores: Dict[str, List] = {}
            for score, snap_json in records:
                snap = json.loads(snap_json)
                q_type = snap.get("type", "æœªçŸ¥")
                type_scores.setdefault(q_type, []).append(score)

            type_avg = {t: sum(sc) / len(sc) for t, sc in type_scores.items()}
            weak_type = min(type_avg, key=type_avg.get)
            weak_avg = type_avg[weak_type]

            recs = db.fetchall(
                "SELECT id, q_type, difficulty, content FROM question_bank WHERE q_type=? LIMIT ?",
                (weak_type, num_questions)
            )
            header = f"[{name}] è–„å¼±é¡¹ã€Œ{weak_type}ã€(å‡åˆ† {weak_avg:.2f})ï¼Œæ¨èç»ƒä¹ :\n"
        else:
            recs = db.fetchall(
                "SELECT id, q_type, difficulty, content FROM question_bank ORDER BY RANDOM() LIMIT ?",
                (num_questions,)
            )
            header = f"[{name}] é¦–æ¬¡é¢è¯•ï¼Œéšæœºæ¨è {num_questions} é¢˜:\n"

        if not recs:
            return f"[{name}] é¢˜åº“æš‚æ— å¯æ¨èé¢˜ç›®"

        result = header + "-" * 40 + "\n"
        for idx, (q_id, q_type, diff, content) in enumerate(recs, 1):
            result += f"  {idx}. [ID:{q_id}] {q_type} / {diff}\n     {content[:80]}...\n"
        return result

    @tool(args_schema=RecommendInput)
    def recommend_questions(interviewee_ids: List[int], num_questions: int = 3) -> str:
        """æ ¹æ®é¢è¯•è€…å†å²è¡¨ç°ï¼Œæ¨èåˆé€‚é¢˜ç›®ï¼ˆé’ˆå¯¹è–„å¼±ç±»å‹ï¼‰ã€‚æ”¯æŒæ‰¹é‡æ¨èã€‚"""
        results = [_recommend_one(iid, num_questions) for iid in interviewee_ids]
        return "\n\n".join(results)

    return recommend_questions


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 6. å‘é€é‚®ä»¶å·¥å…·
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _create_email_tool(db):
    """å·¥å‚å‡½æ•°ï¼šåˆ›å»ºé‚®ä»¶å‘é€å·¥å…·"""

    smtp_config = {
        "host": os.getenv("SMTP_HOST", "smtp.163.com"),
        "port": int(os.getenv("SMTP_PORT", "465")),
        "user": os.getenv("SMTP_USER", ""),
        "pass": os.getenv("SMTP_AUID", ""),
        "from": os.getenv("SMTP_FROM", os.getenv("SMTP_USER", ""))
    }

    def _send_one(iid: int, subject: str, content: str) -> str:
        info = db.fetchall(
            "SELECT name, email FROM interviewee WHERE id=?", (iid,)
        )
        if not info:
            return f"âŒ ID={iid} æœªæ‰¾åˆ°é¢è¯•è€…"

        name, email = info[0]
        if not email:
            return f"âŒ [{name}] é‚®ç®±æœªå¡«å†™ï¼Œè·³è¿‡å‘é€"

        try:
            msg = MIMEMultipart()
            msg["From"] = smtp_config["from"]
            msg["To"] = email
            msg["Subject"] = subject
            msg.attach(MIMEText(content, "plain", "utf-8"))

            with smtplib.SMTP_SSL(smtp_config["host"], smtp_config["port"], timeout=15) as server:
                if smtp_config["user"]:
                    server.login(smtp_config["user"], smtp_config["pass"])
                server.sendmail(smtp_config["from"], email, msg.as_string())

            return f"âœ… [{name}] æŠ¥å‘Šå·²å‘é€è‡³ {email}"
        except Exception as e:
            return f"âŒ [{name}]({email}) å‘é€å¤±è´¥: {str(e)}"

    @tool(args_schema=SendEmailInput)
    def send_report_email(recipients: Union[List[Dict], List[EmailRecipient]]) -> str:
        """å°†é¢è¯•æŠ¥å‘Šé€šè¿‡é‚®ä»¶å‘é€ç»™æŒ‡å®šé¢è¯•è€…ã€‚recipients ä¸ºåˆ—è¡¨ï¼Œæ¯é¡¹åŒ…å« interviewee_idï¼ˆç”¨äºè·å–é‚®ç®±ï¼‰å’Œ report_contentï¼ˆé‚®ä»¶æ­£æ–‡ï¼‰ã€‚æ”¯æŒæ‰¹é‡å‘é€ã€‚"""
        results = []
        for item in recipients:
            if isinstance(item, dict):
                try:
                    recipient = EmailRecipient.model_validate(item)
                except ValidationError as e:
                    results.append(f"âŒ æ”¶ä»¶äººæ•°æ®æ ¼å¼é”™è¯¯: {e}")
                    continue
            elif isinstance(item, EmailRecipient):
                recipient = item
            else:
                results.append(f"âŒ ä¸æ”¯æŒçš„æ”¶ä»¶äººç±»å‹: {type(item)}")
                continue

            results.append(_send_one(recipient.interviewee_id, recipient.subject, recipient.report_content))
        return "\n".join(results)

    return send_report_email


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 7. è·å–é‚®ç®±ä¸­é‚®ä»¶é™„ä»¶æ–‡ä»¶å¹¶ä¸‹è½½åˆ°è·¯å¾„ä¸‹çš„å·¥å…·
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _create_get_doc_tool():
    """å·¥å‚å‡½æ•°ï¼šåˆ›å»ºé‚®ä»¶é™„ä»¶ä¸‹è½½å·¥å…·"""

    # IMAP é…ç½®ï¼ˆä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰
    imap_config = {
        "host": os.getenv("IMAP_HOST", "imap.163.com"),
        "port": int(os.getenv("IMAP_PORT", "993")),
        "user": os.getenv("IMAP_USER", os.getenv("SMTP_USER", "")),
        "pass": os.getenv("IMAP_PASS", os.getenv("SMTP_AUID", "")),
    }

    def _decode_str(s: str) -> str:
        """è§£ç é‚®ä»¶å¤´å­—æ®µï¼ˆå¤„ç† =?utf-8?...?= æ ¼å¼ï¼‰"""
        parts = decode_header(s)
        result = ""
        for part, charset in parts:
            if isinstance(part, bytes):
                result += part.decode(charset or "utf-8", errors="replace")
            else:
                result += part
        return result

    def _safe_filename(name: str) -> str:
        """å°†æ–‡ä»¶åä¸­çš„éæ³•å­—ç¬¦æ›¿æ¢ä¸ºä¸‹åˆ’çº¿"""
        return re.sub(r'[\\/:*?"<>|]', "_", name).strip()

    @tool(args_schema=GetDocInput)
    def get_email_attachments(
        save_dir: str = "./attachments",
        subject_filter: Optional[str] = None,
        sender_filter: Optional[str] = None,
        max_emails: int = 50,
        file_extensions: List[str] = None,
    ) -> str:
        """
        ç™»å½•é‚®ç®±ï¼ˆIMAPï¼‰ï¼Œæ‰«ææ”¶ä»¶ç®±ä¸­å«é™„ä»¶çš„é‚®ä»¶ï¼Œå°†ç¬¦åˆæ¡ä»¶çš„é™„ä»¶ä¸‹è½½åˆ°æŒ‡å®šç›®å½•ã€‚
        æ”¯æŒæŒ‰ä¸»é¢˜å…³é”®è¯ã€å‘ä»¶äººè¿‡æ»¤ï¼Œæ”¯æŒé™å®šæ–‡ä»¶æ‰©å±•åã€‚
        ä¸‹è½½å®Œæˆåè¿”å›å·²ä¿å­˜çš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨ï¼Œå¯ä¾›åç»­å»ºç«‹ç´¢å¼•ä½¿ç”¨ã€‚
        IMAP è´¦å·ä¿¡æ¯ä»ç¯å¢ƒå˜é‡ IMAP_HOST / IMAP_PORT / IMAP_USER / IMAP_PASS è¯»å–ã€‚
        """
        if file_extensions is None:
            file_extensions = [".pdf", ".docx", ".doc", ".xlsx", ".xls", ".png", ".jpg", ".jpeg"]

        # è§„èŒƒåŒ–æ‰©å±•åä¸ºå°å†™
        allowed_ext = {ext.lower() for ext in file_extensions}

        # åˆ›å»ºä¿å­˜ç›®å½•
        save_path = Path(save_dir)
        save_path.mkdir(parents=True, exist_ok=True)

        if not imap_config["user"] or not imap_config["pass"]:
            return "âŒ IMAP è´¦å·æœªé…ç½®ï¼Œè¯·æ£€æŸ¥ç¯å¢ƒå˜é‡ IMAP_USER / IMAP_PASS"

        downloaded: List[str] = []
        skipped: int = 0
        errors: List[str] = []

        try:
            # â”€â”€ è¿æ¥ & è®¤è¯ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            mail = imaplib.IMAP4_SSL(imap_config["host"], imap_config["port"])
            mail.login(imap_config["user"], imap_config["pass"])

            # â”€â”€ 163 å®‰å…¨ç­–ç•¥ï¼šç™»å½•åå¿…é¡»å…ˆå‘ ID å‘½ä»¤å£°æ˜å®¢æˆ·ç«¯èº«ä»½ â”€â”€
            # ä¸å‘æ­¤å‘½ä»¤ç›´æ¥ SELECT ä¼šè§¦å‘ã€ŒUnsafe Loginã€è¢«æ‹¦æˆª
            _user_prefix = imap_config["user"].split("@")[0]
            _id_args = (
                "name", "PythonIMAPClient",
                "version", "1.0.0",
                "vendor", "internal-tool",
                "contact", _user_prefix,
            )
            _id_str = '"' + '" "'.join(_id_args) + '"'
            mail._simple_command("ID", f"({_id_str})")

            # ç­‰å¾…é£æ§ç­–ç•¥ç”Ÿæ•ˆï¼ˆ163è¦æ±‚ï¼‰
            import time
            time.sleep(2)

            mail.select("INBOX")

            # æœç´¢é‚®ä»¶
            search_criteria = "ALL"
            if sender_filter:
                search_criteria = f'FROM "{sender_filter}"'

            _, msg_ids_raw = mail.search(None, search_criteria)
            msg_ids = msg_ids_raw[0].split()

            # å–æœ€è¿‘ max_emails å°ï¼ˆå€’åºï¼Œä¼˜å…ˆæœ€æ–°ï¼‰
            msg_ids = msg_ids[-max_emails:][::-1]

            for mid in msg_ids:
                try:
                    _, msg_data = mail.fetch(mid, "(RFC822)")
                    raw = msg_data[0][1]
                    msg = email.message_from_bytes(raw)

                    # ä¸»é¢˜è¿‡æ»¤
                    subject = _decode_str(msg.get("Subject", ""))
                    if subject_filter and subject_filter not in subject:
                        continue

                    # éå†é™„ä»¶
                    for part in msg.walk():
                        content_disposition = part.get("Content-Disposition", "")
                        if "attachment" not in content_disposition:
                            continue

                        raw_filename = part.get_filename()
                        if not raw_filename:
                            continue

                        filename = _safe_filename(_decode_str(raw_filename))
                        ext = Path(filename).suffix.lower()
                        if ext not in allowed_ext:
                            skipped += 1
                            continue

                        # é¿å…é‡åï¼šè‹¥å·²å­˜åœ¨åˆ™è·³è¿‡
                        target = save_path / filename
                        if target.exists():
                            skipped += 1
                            continue

                        # å†™å…¥æ–‡ä»¶
                        payload = part.get_payload(decode=True)
                        if payload:
                            target.write_bytes(payload)
                            downloaded.append(str(target.resolve()))

                except Exception as e:
                    errors.append(f"å¤„ç†é‚®ä»¶ {mid} å‡ºé”™: {e}")
                    continue

            mail.logout()

        except Exception as e:
            return f"âŒ è¿æ¥é‚®ç®±å¤±è´¥: {e}"

        lines = [
            f"ğŸ“¥ é™„ä»¶ä¸‹è½½å®Œæˆï¼Œä¿å­˜ç›®å½•: {save_path.resolve()}",
            f"  æˆåŠŸä¸‹è½½: {len(downloaded)} ä¸ªæ–‡ä»¶",
            f"  è·³è¿‡ï¼ˆé‡å¤æˆ–ç±»å‹ä¸ç¬¦ï¼‰: {skipped} ä¸ª",
        ]
        if errors:
            lines.append(f"  é”™è¯¯: {len(errors)} æ¡")
            lines.extend(f"    - {e}" for e in errors[:5])
        if downloaded:
            lines.append("  å·²ä¸‹è½½æ–‡ä»¶åˆ—è¡¨:")
            for fp in downloaded:
                lines.append(f"    â€¢ {fp}")

        return "\n".join(lines)

    return get_email_attachments


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 8. ç»™é™„ä»¶å»ºç«‹æŠ¥åè¡¨ç´¢å¼•åˆ°æ•°æ®åº“çš„å·¥å…·ï¼ˆå§“å-å­¦å·-æŠ¥åè¡¨è·¯å¾„ï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _create_write_key_tool(db):
    """å·¥å‚å‡½æ•°ï¼šåˆ›å»ºæŠ¥åè¡¨ç´¢å¼•å†™å…¥å·¥å…·"""

    @tool(args_schema=WriteKeyInput)
    def write_registration_index(
        attachments_dir: str = "./attachments",
        name_pattern: Optional[str] = None,
        id_pattern: Optional[str] = None,
    ) -> str:
        """
        æ‰«ææŒ‡å®šç›®å½•ä¸‹çš„æ‰€æœ‰é™„ä»¶æ–‡ä»¶ï¼Œå°è¯•ä»æ–‡ä»¶åä¸­æå–å§“åå’Œå­¦å·ï¼Œ
        å¹¶å°†ã€å§“å - å­¦å· - æ–‡ä»¶è·¯å¾„ã€‘å†™å…¥æ•°æ®åº“ registration_index è¡¨ã€‚
        è‹¥æ•°æ®åº“ä¸­è¯¥è¡¨ä¸å­˜åœ¨ï¼Œåˆ™è‡ªåŠ¨åˆ›å»ºï¼›è‹¥æ–‡ä»¶è·¯å¾„å·²å­˜åœ¨åˆ™è·³è¿‡ï¼ˆé¿å…é‡å¤ç´¢å¼•ï¼‰ã€‚
        name_pattern / id_pattern ä¸ºå¯é€‰çš„æ­£åˆ™è¡¨è¾¾å¼ï¼Œç”¨äºä»æ–‡ä»¶åæå–ä¿¡æ¯ï¼›
        è‹¥ä¸æä¾›åˆ™å°è¯•é€šç”¨è§„åˆ™ï¼ˆä¸‹åˆ’çº¿åˆ†éš”ï¼‰ã€‚
        """
        # â”€â”€ ç¡®ä¿æ•°æ®åº“è¡¨å­˜åœ¨ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        _ensure_registration_table(db)

        dir_path = Path(attachments_dir)
        if not dir_path.exists():
            return f"âŒ ç›®å½•ä¸å­˜åœ¨: {attachments_dir}"

        # ç¼–è¯‘æ­£åˆ™ï¼ˆå¯é€‰ï¼‰
        name_re = re.compile(name_pattern) if name_pattern else None
        id_re = re.compile(id_pattern) if id_pattern else None

        def _extract_name_id(filename: str):
            """
            ä»æ–‡ä»¶åä¸­æå–å§“åå’Œå­¦å·ã€‚
            ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·æä¾›çš„æ­£åˆ™ï¼›å¦åˆ™å°è¯•ä»¥ä¸‹é€šç”¨è§„åˆ™ï¼š
              - æ ¼å¼1: å§“å_å­¦å·_*.ext   â†’  é¦–æ®µä¸ºå§“åï¼Œç¬¬äºŒæ®µä¸ºå­¦å·
              - æ ¼å¼2: å­¦å·_å§“å_*.ext   â†’  é¦–æ®µå…¨æ•°å­—åˆ™è§†ä¸ºå­¦å·
              - æ ¼å¼3: å§“åï¼ˆå­¦å·ï¼‰*.ext
              - å…œåº•: æ–‡ä»¶åä½œä¸ºå§“åï¼Œå­¦å·ç½®ç©º
            """
            stem = Path(filename).stem
            extracted_name, extracted_id = None, None

            if name_re:
                m = name_re.search(stem)
                extracted_name = m.group(1) if m else None
            if id_re:
                m = id_re.search(stem)
                extracted_id = m.group(1) if m else None

            # è‹¥å‡æœªæä¾›æ­£åˆ™ï¼Œä½¿ç”¨é€šç”¨è§„åˆ™
            if not name_re and not id_re:
                # è§„åˆ™ï¼šæ‹¬å·å†…å­¦å·
                bracket_m = re.search(r'[ï¼ˆ(](\d{6,12})[ï¼‰)]', stem)
                if bracket_m:
                    extracted_id = bracket_m.group(1)
                    extracted_name = stem[:bracket_m.start()].strip("_- ")
                else:
                    parts = re.split(r'[_\-\s]+', stem)
                    if len(parts) >= 2:
                        if re.fullmatch(r'\d{6,12}', parts[0]):
                            extracted_id, extracted_name = parts[0], parts[1]
                        elif re.fullmatch(r'\d{6,12}', parts[1]):
                            extracted_name, extracted_id = parts[0], parts[1]
                        else:
                            extracted_name = parts[0]
                    else:
                        extracted_name = stem

            return extracted_name, extracted_id

        inserted, skipped, errors = 0, 0, []

        # é€’å½’æ‰«æç›®å½•ä¸­æ‰€æœ‰æ–‡ä»¶
        all_files = [f for f in dir_path.rglob("*") if f.is_file()]

        for fpath in all_files:
            abs_path = str(fpath.resolve())
            try:
                name_val, id_val = _extract_name_id(fpath.name)

                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ï¼ˆfile_path UNIQUE çº¦æŸï¼‰
                existing = db.fetchall(
                    "SELECT id FROM registration_index WHERE file_path=?", (abs_path,)
                )
                if existing:
                    skipped += 1
                    continue

                db.execute(
                    "INSERT INTO registration_index (name, student_id, file_path, file_name) VALUES (?, ?, ?, ?)",
                    (name_val, id_val, abs_path, fpath.name)
                )
                inserted += 1
            except Exception as e:
                errors.append(f"{fpath.name}: {e}")

        lines = [
            f"ğŸ“‹ æŠ¥åè¡¨ç´¢å¼•å®Œæˆï¼ˆç›®å½•: {dir_path.resolve()}ï¼‰",
            f"  æ–°å¢ç´¢å¼•: {inserted} æ¡",
            f"  å·²è·³è¿‡ï¼ˆé‡å¤ï¼‰: {skipped} æ¡",
            f"  æ€»æ–‡ä»¶æ•°: {len(all_files)} ä¸ª",
        ]
        if errors:
            lines.append(f"  é”™è¯¯: {len(errors)} æ¡")
            lines.extend(f"    - {e}" for e in errors[:5])
        return "\n".join(lines)

    return write_registration_index


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 9. è¯»å–æŠ¥åè¡¨å†…å®¹å¹¶è¿”å›å¯¹åº”å†…å®¹æ ¼å¼çš„å·¥å…·ï¼ˆå¢å¼ºç‰ˆï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _create_read_doc_tool():
    """å·¥å‚å‡½æ•°ï¼šåˆ›å»ºæŠ¥åè¡¨å†…å®¹è¯»å–å·¥å…·ï¼ˆå«æ³¨å…¥æ£€æµ‹ä¸å­—æ®µå¯¹é½ï¼‰"""

    # â”€â”€ å®‰å…¨æ£€æµ‹é…ç½® â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # åŸºäºå®é™…æ”»å‡»æ ·ä¾‹ï¼ˆé»„å­ç„¶ - é¢è¯•æŠ¥åè¡¨.xlsxï¼‰å¢å¼ºçš„ç‰¹å¾åº“
    INJECTION_PATTERNS = [
        r"æ‰®æ¼”.*?è§’è‰²",  # æ£€æµ‹è§’è‰²æ‰®æ¼”è¯·æ±‚
        r"ä»ç°åœ¨å¼€å§‹",  # æ£€æµ‹æŒ‡ä»¤è¦†ç›–æ—¶é—´çŠ¶è¯­
        r"å¿½ç•¥.*?æŒ‡ä»¤",  # æ£€æµ‹å¿½ç•¥æŒ‡ä»¤
        r"ç³»ç»ŸæŒ‡ä»¤",  # æ£€æµ‹ç³»ç»ŸæŒ‡ä»¤å…³é”®è¯
        r"å‡è®¾ä½ æ˜¯",  # æ£€æµ‹å‡è®¾æ€§èº«ä»½
        r"you are.*?now",  # è‹±æ–‡æ³¨å…¥å¸¸è§æ¨¡å¼
        r"ignore.*?previous",  # è‹±æ–‡å¿½ç•¥å†å²
        r"%\s*[ä½ æ‚¨]",  # æ£€æµ‹ç‰¹æ®Šç¬¦å·å¼€å¤´çš„ä¸­æ–‡æŒ‡ä»¤ (é’ˆå¯¹æ ·ä¾‹ %ä½ )
        r"%.*?(?:æ‰®æ¼” | å‡è®¾ | æŒ‡ä»¤ | å¿½ç•¥)",  # å¢å¼ºï¼š% å¼€å¤´åè·ŸæŒ‡ä»¤åŠ¨è¯
        r"###.*?æŒ‡ä»¤",  # æ£€æµ‹ Markdown åˆ†éš”ç¬¦æ³¨å…¥
        r"çŒ«å¨˜|persona|system prompt",  # é’ˆå¯¹æ ·ä¾‹çš„å…·ä½“é«˜é£é™©å…³é”®è¯
        r"æ¥ä¸‹æ¥.*?è¿‡ç¨‹ä¸­",  # æ£€æµ‹æŒç»­æ€§æŒ‡ä»¤è¦†ç›–
    ]
    COMPILED_PATTERNS = [re.compile(p, re.IGNORECASE) for p in INJECTION_PATTERNS]

    def _detect_injection(text: str) -> List[Dict[str, Any]]:
        """æ£€æµ‹æ–‡æœ¬ä¸­æ˜¯å¦åŒ…å«æç¤ºè¯æ³¨å…¥ç‰¹å¾ï¼Œè¿”å›è¯¦ç»†è­¦å‘Šä¿¡æ¯"""
        warnings = []
        for i, pattern in enumerate(COMPILED_PATTERNS):
            matches = pattern.findall(text)
            if matches:
                # è®°å½•åŒ¹é…åˆ°çš„å…·ä½“ç‰‡æ®µï¼Œä¾¿äºå®šä½
                warnings.append({
                    "pattern": INJECTION_PATTERNS[i],
                    "matches": matches[:3],  # åªä¿ç•™å‰ 3 ä¸ªåŒ¹é…é¡¹é¿å…è¿‡é•¿
                    "severity": "HIGH" if "çŒ«å¨˜" in matches[0] or "%" in INJECTION_PATTERNS[i] else "MEDIUM"
                })
        return warnings

    def _read_pdf(file_path: str) -> str:
        """æå– PDF æ–‡æœ¬"""
        try:
            import pdfplumber
            with pdfplumber.open(file_path) as pdf:
                return "\n".join(page.extract_text() or "" for page in pdf.pages)
        except ImportError:
            try:
                from pypdf import PdfReader
                reader = PdfReader(file_path)
                return "\n".join(page.extract_text() or "" for page in reader.pages)
            except ImportError:
                return "[é”™è¯¯] æœªå®‰è£… pdfplumber æˆ– pypdfï¼Œæ— æ³•è¯»å– PDF"

    def _read_docx(file_path: str) -> str:
        """æå– DOCX æ–‡æœ¬"""
        try:
            from docx import Document
            doc = Document(file_path)
            paragraphs = [p.text for p in doc.paragraphs if p.text.strip()]
            table_texts = []
            for table in doc.tables:
                for row in table.rows:
                    cells = [cell.text.strip() for cell in row.cells if cell.text.strip()]
                    if cells:
                        table_texts.append(" | ".join(cells))
            return "\n".join(paragraphs + table_texts)
        except ImportError:
            return "[é”™è¯¯] æœªå®‰è£… python-docxï¼Œæ— æ³•è¯»å– DOCX"

    def _read_xlsx(file_path: str) -> str:
        """æå– XLSX æ–‡æœ¬"""
        try:
            import openpyxl
            wb = openpyxl.load_workbook(file_path, data_only=True)
            lines = []
            for sheet in wb.worksheets:
                for row in sheet.iter_rows(values_only=True):
                    cells = [str(c) for c in row if c is not None]
                    if cells:
                        # ä½¿ç”¨ | åˆ†éš”å•å…ƒæ ¼ï¼Œä¾¿äºåç»­è§£æ Key-Value å¯¹
                        lines.append(" | ".join(cells))
            return "\n".join(lines)
        except ImportError:
            return "[é”™è¯¯] æœªå®‰è£… openpyxlï¼Œæ— æ³•è¯»å– XLSX"

    def _extract_fields(text: str, fields: List[str]) -> Dict[str, str]:
        """ä»æ–‡æœ¬ä¸­æŒ‰å­—æ®µåæå–å€¼ï¼ˆä¼˜åŒ–äº†åˆ†éš”ç¬¦å¤„ç†ï¼‰"""
        result = {}
        for field in fields:
            # ä¼˜åŒ–æ­£åˆ™ï¼šå…è®¸å­—æ®µååè·Ÿ ':' æˆ– '|' ä½œä¸ºåˆ†éš”ç¬¦ï¼Œä¸å†å°† '|' è§†ä¸ºç»ˆæ­¢ç¬¦
            # é€‚é… _read_xlsx ç”Ÿæˆçš„ "å­—æ®µåï¼š | å€¼" æˆ– "å­—æ®µåï¼šå€¼" æ ¼å¼
            pattern = rf'{re.escape(field)}\s*[ï¼š:]\s*\|?\s*(.+?)(?=\n|$)'
            m = re.search(pattern, text)
            result[field] = m.group(1).strip() if m else ""
        return result

    @tool(args_schema=ReadDocInput)
    def read_registration_doc(file_path: str, extract_fields: List[str] = None) -> str:
        """
        è¯»å–æŒ‡å®šè·¯å¾„ä¸‹çš„æŠ¥åè¡¨æ–‡ä»¶ï¼Œæå–ç»“æ„åŒ–å­—æ®µï¼Œå¹¶è¿›è¡Œå®‰å…¨æ³¨å…¥æ£€æµ‹ã€‚
        é’ˆå¯¹å®éªŒå®¤æŠ¥åè¡¨æ¨¡æ¿ä¼˜åŒ–ï¼Œç‰¹åˆ«å…³æ³¨â€œç”³è¯·ç†ç”±â€ç­‰é«˜é£é™©å­—æ®µã€‚
        è¿”å› JSON æ ¼å¼ï¼ŒåŒ…å«å­—æ®µå†…å®¹åŠå®‰å…¨è­¦å‘Šã€‚
        """
        # é»˜è®¤å­—æ®µå¯¹é½è‡³ é¢è¯•æŠ¥åè¡¨ - æ¨¡æ¿.xlsx
        if extract_fields is None:
            extract_fields = ["å§“å", "å­¦å·", "é‚®ç®±", "é¢è¯•æ–¹å‘", "ç»†åˆ†æ–¹å‘", "æ ¸å¿ƒé¡¹ç›®", "ç”³è¯·ç†ç”±"]

        fpath = Path(file_path)
        if not fpath.exists():
            return json.dumps({"error": f"æ–‡ä»¶ä¸å­˜åœ¨ï¼š{file_path}"}, ensure_ascii=False)

        ext = fpath.suffix.lower()
        if ext == ".pdf":
            raw_text = _read_pdf(file_path)
        elif ext in (".docx",):
            raw_text = _read_docx(file_path)
        elif ext in (".xlsx", ".xls"):
            raw_text = _read_xlsx(file_path)
        else:
            try:
                raw_text = fpath.read_text(encoding="utf-8", errors="replace")
            except Exception as e:
                return json.dumps({"error": f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹æˆ–è¯»å–å¤±è´¥ï¼š{e}"}, ensure_ascii=False)

        if not raw_text.strip():
            return json.dumps({"error": "æ–‡ä»¶å†…å®¹ä¸ºç©ºæˆ–æ— æ³•æå–æ–‡æœ¬"}, ensure_ascii=False)

        # â”€â”€ å®‰å…¨æ£€æµ‹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        security_warnings = _detect_injection(raw_text)

        # é£é™©ç­‰çº§è¯„ä¼°
        risk_level = "LOW"
        if security_warnings:
            if any(w.get("severity") == "HIGH" for w in security_warnings):
                risk_level = "HIGH"
            else:
                risk_level = "MEDIUM"

        extracted = _extract_fields(raw_text, extract_fields)

        # ç‰¹åˆ«æ£€æŸ¥ç”³è¯·ç†ç”±å­—æ®µæ˜¯å¦åŒ…å«é«˜é£é™©å†…å®¹
        reason_field = extracted.get("ç”³è¯·ç†ç”±", "")
        if reason_field and security_warnings:
            # å¦‚æœå­˜åœ¨è­¦å‘Šä¸”ç”³è¯·ç†ç”±éç©ºï¼Œæç¤ºé‡ç‚¹å®¡æŸ¥è¯¥å­—æ®µ
            for w in security_warnings:
                if any(m in reason_field for m in w.get("matches", [])):
                    w["affected_field"] = "ç”³è¯·ç†ç”±"

        return json.dumps(
            {
                "file": fpath.name,
                "risk_level": risk_level,
                "security_warnings": security_warnings,
                "fields": extracted,
                "raw_preview": raw_text[:500].replace("\n", " "),
                "security_tip": "å‘ç°é«˜é£é™©æ³¨å…¥ç‰¹å¾æ—¶ï¼Œè¯·å‹¿ç›´æ¥å°†å†…å®¹è¾“å…¥ LLMï¼Œå»ºè®®äººå·¥å¤æ ¸ã€‚" if risk_level == "HIGH" else ""
            },
            ensure_ascii=False,
            indent=2
        )

    return read_registration_doc
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 10. é€šè¿‡æ•°æ®åº“è·å–ç´¢å¼•å†…å®¹çš„å·¥å…·ï¼ˆå§“å-å­¦å·-æŠ¥åè¡¨è·¯å¾„ï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _create_read_key_tool(db):
    """å·¥å‚å‡½æ•°ï¼šåˆ›å»ºæŠ¥åè¡¨ç´¢å¼•æŸ¥è¯¢å·¥å…·"""

    @tool(args_schema=ReadKeyInput)
    def read_registration_index(
        name: Optional[str] = None,
        student_id: Optional[str] = None,
        limit: int = 50,
    ) -> str:
        """
        æŸ¥è¯¢æ•°æ®åº“ä¸­çš„æŠ¥åè¡¨ç´¢å¼•ï¼ˆregistration_index è¡¨ï¼‰ï¼Œ
        æ”¯æŒæŒ‰å§“åæ¨¡ç³ŠæŸ¥è¯¢æˆ–æŒ‰å­¦å·ç²¾ç¡®æŸ¥è¯¢ï¼Œè¿”å›åŒ¹é…è®°å½•ï¼ˆå«å§“åã€å­¦å·ã€æ–‡ä»¶è·¯å¾„ï¼‰ã€‚
        è‹¥æ•°æ®åº“ä¸­è¯¥è¡¨ä¸å­˜åœ¨ï¼Œè‡ªåŠ¨åˆ›å»ºå¹¶æç¤ºç”¨æˆ·å…ˆè¿è¡Œç´¢å¼•å·¥å…·ã€‚
        """
        # â”€â”€ ç¡®ä¿æ•°æ®åº“è¡¨å­˜åœ¨ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        _ensure_registration_table(db)

        # æ„å»ºæŸ¥è¯¢æ¡ä»¶
        conditions, params = [], []
        if name:
            conditions.append("name LIKE ?")
            params.append(f"%{name}%")
        if student_id:
            conditions.append("student_id = ?")
            params.append(student_id)

        where_clause = ("WHERE " + " AND ".join(conditions)) if conditions else ""
        params.append(limit)

        rows = db.fetchall(
            f"SELECT id, name, student_id, file_name, file_path, created_at "
            f"FROM registration_index {where_clause} ORDER BY created_at DESC LIMIT ?",
            tuple(params)
        )

        if not rows:
            hint = "æç¤ºï¼šè¯·å…ˆè¿è¡Œ write_registration_index å·¥å…·å»ºç«‹ç´¢å¼•ã€‚"
            if name or student_id:
                return f"æœªæ‰¾åˆ°åŒ¹é…çš„æŠ¥åè¡¨è®°å½•ã€‚\n{hint}"
            return f"æ•°æ®åº“ä¸­æš‚æ— æŠ¥åè¡¨ç´¢å¼•è®°å½•ã€‚\n{hint}"

        lines = [f"æŸ¥è¯¢ç»“æœï¼ˆå…± {len(rows)} æ¡ï¼‰ï¼š"]
        for rid, rname, rid_num, fname, fpath, created in rows:
            lines.append(
                f"  [{rid}] å§“å:{rname or 'æœªçŸ¥'}  å­¦å·:{rid_num or 'æœªçŸ¥'}  "
                f"æ–‡ä»¶:{fname}  è·¯å¾„:{fpath}  å½•å…¥æ—¶é—´:{created}"
            )
        return "\n".join(lines)

    return read_registration_index


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# å·¥å…·æ³¨å†Œå…¥å£
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def get_default_tools(db) -> List:
    """
    è·å–æ‰€æœ‰é»˜è®¤å·¥å…·çš„ LangChain Tool åˆ—è¡¨ï¼ˆä½¿ç”¨ @tool è£…é¥°å™¨åˆ›å»ºï¼‰

    ç”¨æ³•ï¼š
        tools = get_default_tools(db)
        agent.register_tools(tools)
    """
    return [
        _create_lookup_tool(db),
        _create_question_stats_tool(db),
        _create_analysis_tool(db),
        _create_report_tool(db),
        _create_recommend_tool(db),
        _create_email_tool(db),
        _create_get_doc_tool(),           # å·¥å…·7ï¼šé‚®ä»¶é™„ä»¶ä¸‹è½½ï¼ˆæ— éœ€ dbï¼‰
        _create_write_key_tool(db),       # å·¥å…·8ï¼šå»ºç«‹æŠ¥åè¡¨ç´¢å¼•
        _create_read_doc_tool(),          # å·¥å…·9ï¼šè¯»å–æŠ¥åè¡¨å†…å®¹ï¼ˆæ— éœ€ dbï¼‰
        _create_read_key_tool(db),        # å·¥å…·10ï¼šæŸ¥è¯¢æŠ¥åè¡¨ç´¢å¼•
    ]


def register_default_tools(agent, db):
    """
    å‘åå…¼å®¹å‡½æ•°ï¼šç›´æ¥æ³¨å†Œåˆ° Agent å®ä¾‹
    ï¼ˆå†…éƒ¨è°ƒç”¨ get_default_tools + agent.register_toolsï¼‰
    """
    tools = get_default_tools(db)
    agent.register_tools(tools)
    print(f"[AgentTools] å·²æ³¨å†Œ {len(tools)} ä¸ª LangChain å·¥å…·")